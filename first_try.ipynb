{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are ten different digits and corresponding ranks from 1 to 10. Training a neural network to return the serial number of digit that has the max value of the sum of three contiguous digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def get_training_set():\n",
    "    size = 10000\n",
    "    file = open('data/problem1_training_set.txt', 'w')\n",
    "    for i in range(size):\n",
    "        array = []\n",
    "        number = 0\n",
    "        while number < 10:\n",
    "            temp = random.randint(0, 100)\n",
    "            if temp not in array:\n",
    "                array.append(temp)\n",
    "                file.write(str(temp) + '\\t')\n",
    "                number += 1\n",
    "#         print(array)\n",
    "        array_3sum = []\n",
    "        for j in range(8):\n",
    "            array_3sum.append(array[j] + array[j + 1] + array[j + 2])\n",
    "#         print(array_3sum)\n",
    "        serial_number = array_3sum.index(max(array_3sum))\n",
    "        file.write(str(serial_number) + '\\n')\n",
    "#         print(serial_number)\n",
    "\n",
    "\n",
    "def read_training_set():\n",
    "    file = open('data/problem1_training_set.txt', 'r')\n",
    "    training_set = file.readlines()\n",
    "    # print(training_set)\n",
    "    data = []\n",
    "    label = []\n",
    "    for i in range(len(training_set)):\n",
    "        numbers = []\n",
    "        j = 0\n",
    "        while j < len(training_set[i]):\n",
    "            num = ''\n",
    "            symbol = training_set[i][j]\n",
    "            while '0' <= symbol <= '9':\n",
    "                num += symbol\n",
    "                j += 1\n",
    "                if j < len(training_set[i]):\n",
    "                    symbol = training_set[i][j]\n",
    "                else:\n",
    "                    break\n",
    "            j += 1\n",
    "            if num != '':\n",
    "                numbers.append(int(num))\n",
    "#         print(numbers)\n",
    "        data.append(numbers[0:10])\n",
    "        label.append(numbers[10])\n",
    "    # print(data)\n",
    "    # print(label)\n",
    "    return data, label\n",
    "\n",
    "get_training_set()\n",
    "data, label = read_training_set()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "size = len(data)\n",
    "print(size)\n",
    "divide = int(0.8 * size)\n",
    "print(divide)\n",
    "training_data = data[0: divide]\n",
    "training_label = label[0: divide]\n",
    "test_data = data[divide: size]\n",
    "test_label = label[divide: size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv): Conv2d(1, 1, kernel_size=(1, 3), stride=(1, 1))\n",
      ")\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "torch.Size([10])\n",
      "torch.Size([1, 1, 1, 10])\n",
      "tensor([[[[1.1029, 1.0303, 0.9577, 0.8851, 0.8125, 0.7399, 0.6673, 0.5947]]]],\n",
      "       grad_fn=<MkldnnConvolutionBackward>)\n",
      "tensor(0)\n",
      "tensor([[[[0.1590, 0.1478, 0.1375, 0.1278, 0.1189, 0.1106, 0.1028, 0.0956]]]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([1.1029, 1.0303, 0.9577, 0.8851, 0.8125, 0.7399, 0.6673, 0.5947],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 1, (1, 3))\n",
    "#         self.pool = nn.MaxPool2d((1, 8))\n",
    "    \n",
    "    def forward1(self, x):\n",
    "        x = self.conv(x)\n",
    "        print(x)\n",
    "#         x = self.pool(x)\n",
    "        x = torch.argmax(x)\n",
    "        return x\n",
    "    \n",
    "    def forward2(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = F.softmax(x, 3)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "input_oral = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "print(input_oral)\n",
    "input_tensor = torch.tensor(input_oral).float()\n",
    "print(input_tensor)\n",
    "print(input_tensor.size())\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "print(input_tensor.size())\n",
    "print(net.forward1(input_tensor))\n",
    "print(net.forward2(input_tensor))\n",
    "print(torch.squeeze(net.forward(input_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 3, 4]])\n",
      "tensor([1, 2])\n",
      "tensor(1.8152)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "print(torch.tensor([[1,2,3], [2,3,4]]))\n",
    "print(torch.tensor([1, 2]))\n",
    "print(criterion(torch.tensor([[1,2,3], [2,3,4]]).float(), torch.tensor([1, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200] loss: 8.620\n",
      "[400] loss: 80.158\n",
      "[600] loss: 64.287\n",
      "[800] loss: 192.427\n",
      "[1000] loss: 34.293\n",
      "[1200] loss: 166.107\n",
      "[1400] loss: 227.011\n",
      "[1600] loss: 196.556\n",
      "[1800] loss: 57.992\n",
      "[2000] loss: 1021.757\n",
      "[2200] loss: 1626.310\n",
      "[2400] loss: 872.695\n",
      "[2600] loss: 682.624\n",
      "[2800] loss: 71.860\n",
      "[3000] loss: 0.000\n",
      "[3200] loss: 0.000\n",
      "[3400] loss: 2130.206\n",
      "[3600] loss: 722.695\n",
      "[3800] loss: 2282.527\n",
      "[4000] loss: 240.056\n",
      "[4200] loss: 552.693\n",
      "[4400] loss: 638.043\n",
      "[4600] loss: 17.878\n",
      "[4800] loss: 0.000\n",
      "[5000] loss: 959.884\n",
      "[5200] loss: 1378.283\n",
      "[5400] loss: 1108.260\n",
      "[5600] loss: 951.549\n",
      "[5800] loss: 690.543\n",
      "[6000] loss: 899.135\n",
      "[6200] loss: 655.900\n",
      "[6400] loss: 0.000\n",
      "[6600] loss: 27.091\n",
      "[6800] loss: 0.000\n",
      "[7000] loss: 892.985\n",
      "[7200] loss: 350.879\n",
      "[7400] loss: 592.293\n",
      "[7600] loss: 1684.366\n",
      "[7800] loss: 1033.265\n",
      "[8000] loss: 1210.588\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda: 1\")\n",
    "\n",
    "for i in range(0, len(training_data), 10):\n",
    "    running_loss = 0.0\n",
    "    training_part_data = torch.tensor(training_data[i: i+10]).float()\n",
    "    training_part_label = torch.tensor(training_label[i: i+10])\n",
    "#     print('i: ', i)   \n",
    "    # mini-batch=10\n",
    "    j = 0\n",
    "    \n",
    "#     net.to(device)\n",
    "#     training_part_data.to(device)\n",
    "#     training_part_label.to(device)\n",
    "    \n",
    "    for training_part in training_part_data:\n",
    "#         training_part.cuda()\n",
    "        training_part = training_part.unsqueeze(0).unsqueeze(0).unsqueeze(0)         \n",
    "        training_part = torch.squeeze(net.forward(training_part)).unsqueeze(0)\n",
    "        if j == 0:\n",
    "            mini_batch_training = training_part\n",
    "        else:\n",
    "            mini_batch_training = torch.cat((mini_batch_training, training_part), dim=0)    \n",
    "        j += 1\n",
    "#     print('mini_batch_training: ', mini_batch_training)\n",
    "#     print('training_part_label: ', training_part_label)\n",
    "    \n",
    "    loss = criterion(mini_batch_training, training_part_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print loss for every 200 samples\n",
    "    running_loss += loss.item()\n",
    "    if (i+10) % 200 == 0:\n",
    "        print('[%d] loss: %.3f' % (i+10, running_loss / 200))\n",
    "        running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "# net = net.cpu()\n",
    "correct = 0\n",
    "for i in range(len(test_data)):\n",
    "    predict = torch.argmax(net.forward(torch.tensor(test_data[i]).float().unsqueeze(0).unsqueeze(0).unsqueeze(0))).item()  \n",
    "    if predict == test_label[i]:\n",
    "          correct+= 1\n",
    "\n",
    "print(\"accuracy: %.3f\" % float(correct/len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[31478.1035, 27751.2598, 22866.7422]]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.5264], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
